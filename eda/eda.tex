\documentclass[aspectratio=169,12pt,t]{beamer}
\usepackage{graphicx}
\setbeameroption{hide notes}
\setbeamertemplate{note page}[plain]
\usepackage{listings}

\input{../LaTeX/header.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% end of header
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% title info
\title{Exploratory data analysis}
\author{\href{https://kbroman.org}{Karl Broman}}
\institute{Biostatistics \& Medical Informatics, UW{\textendash}Madison}
\date{\href{https://kbroman.org}{\tt \scriptsize \color{foreground} kbroman.org}
\\[-4pt]
\href{https://github.com/kbroman}{\tt \scriptsize \color{foreground} github.com/kbroman}
\\[-4pt]
\href{https://twitter.com/kwbroman}{\tt \scriptsize \color{foreground} @kwbroman}
\\[-4pt]
{\scriptsize Slides: \href{https://kbroman.org/BMI773/eda.pdf}{\tt kbroman.org/BMI773/eda.pdf}}
}


\begin{document}

% title slide
{
\setbeamertemplate{footline}{} % no page number here
\frame{
  \titlepage

\note{
   This lecture concerns exploratory data analysis. Techniques for the
   creative investigation of data, to identify problems and generate
   ideas.
}
} }








\begin{frame}[c]{}

\only<1>{
  \Large
  \color{title}
  \centering
  What is exploratory data analysis?
}

\only<2|handout 0>{
  \bigskip \bigskip

  \figh{Figs/eda_cover.jpg}{0.95}
}

\note{
  What is exploratory data analysis? The term comes from John Tukey.
  For that matter the term ``data analysis'' itself is from Tukey.

  I think he would contrast it with say ``confirmatory'' data
  analysis. Exploratory data analysis is all about creative
  investigation to generate new ideas. Confirmatory data analysis is
  about answering specific questions.
}
\end{frame}








\begin{frame}{What is exploratory data analysis?}

\bigskip \bigskip \bigskip

{\color{title}  Tukey:} \, \, Looking at data to see what it seems to say.

\onslide<2>{
\bigskip \bigskip \bigskip

\hfill \begin{minipage}{0.865\textwidth}
  It is important to understand what you {\hilit can do} \\
  before you learn to measure how {\hilit well} you seem to have
  {\hilit done} it.
\end{minipage}
}

\note{
  Here is what Tukey says in the preface of his book. He defines
  exploratory data analysis as ``looking at data to see what it seems
  to say.''
}
\end{frame}








\begin{frame}{Uses of EDA}

  \bbi
\item Get a sense of things
\item Data diagnostics (quality control)
\item Hoping for an ``a-ha'' moment
\item Following up ``huh'' moments
  \ei

\note{
  What is exploratory data analysis good for?

  Personally, I'm either trying to get a sense of things (as Tukey
  said, figure out what is it that you can do with the data), or I'm
  trying to identify potential problems in the data (data cleaning).

  I'm usually hoping that my explorations will lead some new insight
  that I wouldn't otherwise have achieved. But in practice, I'm
  usually following up on some puzzling aspect of the problem.
}
\end{frame}








\begin{frame}{Data diagnostics: principles}

  \vspace{-7mm}

  \bbi
\item What might have gone wrong?
\item How could it be revealed?
\item Make lots of plots
  \bi
\item scatterplots
\item plots against time
\item consider taking logs
  \ei
\item Check consistency between files
\item Re-calculate derived variables and check that they match
\item Outliers
  \bi
\item Real or error?
\item Are the results affected?
  \ei
\onslide<2>{\item \hilit Don't trust anyway, including yourself}
  \ei

\note{
  Let's start by looking at data diagnostics, sometimes called data
  cleaning. Our goal is to identify problems in the data, and I feel
  the best way to do that is to anticipate the problems and target
  them specifically: what might have gone wrong? how can we tell?

  But further, just make lots of plots. For high-dimensional data it
  can be tricky. Think about how to summarize the results in ways that
  can reveal the sorts of odd problems. But just make lots of
  scatterplots and plots of variables against time. For measurements
  that span multiple orders of magnitude, you usually want to take
  logs.

  Also, check consistency between files. If subjects are present in
  one file but missing from another, is that as expected or could part
  of a file be missing? If measurements are repeated in multiple
  files, do they match? Re-calculate any derived variables and check
  that they match.

  For outliers, you want to figure out if they are real or an error.
  Do they affect the results? If they're errors, fix them. If they're
  real but don't affect the results, no worries. If they're real and
  affect the results, worry.
}
\end{frame}


\begin{frame}[c]{Batch effect}

\only<1|handout 0>{\figh{Figs/il3.pdf}{0.85}}
\only<2>{\figh{Figs/il3_log.pdf}{0.85}}

\note{
Here's an example of a clear batch effect. You can really only tell if
you plot the variable by the order of measurement, and it's much more
clear if you take logs.
}

\end{frame}





\begin{frame}[c]{Messed up units}

\figh{Figs/adipose_weight.pdf}{0.85}

\note{
Here's a case where a variable was recorded in the wrong units (g
rather than mg) for a few individuals)

}

\end{frame}




\begin{frame}[c]{Outliers}

\figh{Figs/body_weight.pdf}{0.85}

\note{
In this particular case, it turned out that the day 10 weights for two
subjects got swapped.

When you look at this sort of situation, ask yourself how you might
find this problem if you have 20 weight measurements and 1500
individuals.
}

\end{frame}




\begin{frame}{Weird stuff I've seen}

  \vspace{-7mm}

  \bbi
  \item 500 worksheet excel file where the middle 100 worksheets have
    the variables arranged in a different order
  \item Weird rounding patterns
  \item Missing values that shouldn't be, because derived values are
    not missing
  \item Categorical data with inconsistent categories
  \item Missing value codes that weren't mentioned and that could be
    real values (e.g., 999)
  \item OMG dates
  \ei

\note{
  All kinds of things get messed up in data files. It's hard to find
  it if you don't look for it; you have to check.

  When it comes to the order of variables in multiple files, {\hilit
  never} assume consistency; {\hilit always} check.
}

\end{frame}




\begin{frame}{Weird rounding}

  \figh{Figs/weird_rounding.png}{0.85}

  \note{
    Here's an example of some weird rounding in an excel file. The
    fonts aren't even consistent. This indicates that some copy and
    pasting went on, which makes me question whether there is some
    other master file that I should really be looking at.
  }

\end{frame}





\begin{frame}{Identifiers}

  \vspace{-7mm}

  \bbi
  \item Are the subject IDs unique?
  \item Are there subject or gene IDs that don't fit the typical
    pattern?
    \bi
  \item {\tt 1e6} vs {\tt 100000}
  \item hyphens turned into periods
  \item IDs that became dates
    \ei
  \item Subjects in one file but not in another and vice versa
  \ei

\note{
  IDs are really important but they can be screwed up in all kinds of
  ways. R can mess them up; Excel can mess them up. They can get
  messed up repeatedly by your collaborators, no matter how hard you
  work to preserve them.
}

\end{frame}






\begin{frame}{Missing values}

  \bbi
  \item As intended?
  \item Below detection limit?
  \item Telling you something about sample quality?
  \item Introducing bias?
  \ei

\note{
  It can be important to look at the pattern of missing data. For
  genotyping and sequencing assays, a high rate of missing data often
  indicates poor quality samples.

  But also, are the missing data really as intended?

  Could they maybe be values below the detection limit of the assay?
  And does that mean that they should be just treated as small values,
  or omitted?

  Is the nature of the missing data going to bias your conclusions?
}

\end{frame}




\begin{frame}{Fitting a model can help}


\note{
  Sometimes, it's helpful to fit some sort of model. Particularly if
  you have very large quantities of data, you could then better
  identify problem samples or data points, for example by looking for
  large residuals.

  Example: mouse body weight data (where fitting smooth curves also
  led us to look at the derivatives, which were super interesting)

}

\end{frame}




\begin{frame}[c]{}


\centerline{\Large Follow up artifacts}

\bigskip \bigskip

\centerline{\large \hilit They might be the most interesting results}


\note{
  A solid lesson I've learned is the importance of following up on
  artifacts.
}

\end{frame}



\begin{frame}[c]{Attie project}


{\hilit
$\sim$500 B6 $\times$ BTBR intercross mice, all ob/ob }

\vspace{6pt}

\begin{itemize}
\itemsep12pt
\item Genotypes at 2057 SNPs (Affymetrix arrays)

\item Gene expression in six tissues (Agilent arrays)

  \begin{itemize}
    \item adipose
    \item gastrocnemius muscle
    \item hypothalamus
    \item pancreatic islets
    \item kidney
    \item liver
  \end{itemize}

\item Numerous clinical phenotypes
  \begin{itemize}
    \item[] (e.g., body weight, insulin and glucose levels)
  \end{itemize}

\end{itemize}

\note{
  When I first got to UW-Madison, I joined a collaboration that was
  carrying out a very large QTL mapping experiment that included about
  500 mice with dense genotype data and numerous clinical phenotypes,
  but also with gene expression data in six different tissues.

  I had mostly been in the back of the room, heckling. But a couple of
  years into the project, I agreed to write the first paper.
}

\end{frame}



\begin{frame}[c]{Intercross}
\figw{Figs/intercross.pdf}{1.0}

\note{
    QTL mapping is an effort to identify the genetic loci that
    contribute to variation in some quantitative trait, like blood
    pressure. Such loci are called quantitative trait loci (QTL).

    We start with two strains that differ in the trait of interest.
    That they show a consistent difference when raised in the same
    environment indicates that the difference is genetic. To try to
    identify genes contributing to the trait difference, we can
    perform a series of different crosses; the most common is the
    intercross.

    One gathers a number of intercross progeny, measures the trait,
    and then measures genotype at different positions along the
    chromosomes. We then look for positions where the genotype is
    associated with the phenotype.
}

\end{frame}




\begin{frame}[c]{Sex and the X chr}
\figh{Figs/xchr_fig.pdf}{0.85}
\note{
  In getting ready to prepare that first paper, I decided to go back
  to the basics and really check that all of the data were in good
  order, starting from the raw genotype files.

  I noticed that there were a number of mice whose X chromosome
  genotype data did not match their sex. The way the cross was carried
  out, female F$_2$ mice will be homozygous BTBR or heterozygous, and
  male F$_2$ mice will be hemizygous (and so look like homyzogous).
  But there were a number of females who were homozygous B6 on the X,
  and a number males who were heterozygous. (Previously, these
  incompatible genotypes had just been omitted.)

  The number of mice with this problem ($\sim$16 out of 500) was not
  large, but it was more than I'd expected, and I sat and pondered how
  to figure out which was correct: sex or genotype.

  I realized that I could maybe use the gene expression data to help.
}
\end{frame}


\begin{frame}[c]{Strong eQTL}
\only<1|handout 0>{\figh{Figs/eqtl_lod_1.pdf}{0.85}}
\only<2>{\figh{Figs/eqtl_lod_2.pdf}{0.85}}
\note{
  In many cases the gene expression traits have very strong genetic
  effects. In particular, for many genes the expression level is
  strongly affected by genotype right at the location of the gene. For
  other genes, expression is strongly affected by genotype at some
  other location. A locus that effects gene expression is called an
  expression QTL or eQTL.
}
\end{frame}

\begin{frame}[c]{E vs G}
\only<1|handout 0>{\figh{Figs/gve1a.pdf}{0.85}}
\only<2>{\figh{Figs/gve1b.pdf}{0.85}}
\note{
  I looked at the gene expression versus genotype at one of these
  eQTL and saw a very strange pattern. There was a very strong
  association, but there were also a lot of mice whose gene expression
  seemed to not match their genotype.

  I mean, there are basically three kinds of mice, expression-wise:
  low, high, or very high. And the low-expression mice are mostly RR,
  while the very-high mice are mostly BB, with the high-expression
  mice being BR. Except there are a bunch of mice that seem to be in
  the wrong ball, expression-wise. And the 16 six-swapped mice include
  9 that are in the wrong ball.

  It's like the sex-swapped mice had been assigned to a random
  genotype. If the genotypes are in the proportions 1:2:1, then we'd
  expected 3/8 to be correct just by chance, which is very similar to
  the 7/16 we see in these data.

  And note that there are 43 mice that look to be in the wrong ball.
  If they are all being assigned genotypes at random, that would
  suggest that there are like 43 $\times$ (8/3) $\approx$ 115 problem
  mice.
}
\end{frame}


\begin{frame}[c]{kNN classifier}
\figh{Figs/gve1c.pdf}{0.85}
\note{
  But we can use the gene expression data to figure out what we
  {\hilit think} each mouse's genotype at this location really is. For
  example, we can create a k-nearest-neighbor classifier, for
  predicting genotype from gene expression.

  If we do this at many strong eQTL, we could potentially reconstruct
  the true genotypes for each mouse, from their expression data.
}
\end{frame}


\begin{frame}[c]{E vs G}
\only<1|handout 0>{\figh{Figs/gve3a.pdf}{0.85}}
\only<2>{\figh{Figs/gve3b.pdf}{0.85}}
\note{
   Many times there will be two different genes whose expression maps
   to a common location. We can look at their expression jointly. In
   many cases, the gene expression clusters are even more clear. And
   again the sex-swapped mice are seen in the wrong ball with
   frequency like 9/16.
}
\end{frame}



\begin{frame}[c]{Basic scheme}
\only<1|handout 0>{\figh{Figs/gve_scheme_1.pdf}{0.85}}
\only<2|handout 0>{\figh{Figs/gve_scheme_2.pdf}{0.85}}
\only<3|handout 0>{\figh{Figs/gve_scheme_3.pdf}{0.85}}
\only<4>{\figh{Figs/gve_scheme_4.pdf}{0.85}}
\note{
   So this leads to our basic scheme for identifying (and correcting)
   the sample mix-ups.

   We first identify a set of expression traits with very strong eQTL.
   We use the expression and corresponding eQTL genotypes to form
   classifiers for predicting eQTL genotype from gene expression. This
   gives us a matrix of inferred eQTL genotypes.

   We then compare the inferred eQTL genotypes to the observed eQTL
   genotypes. If a sample's observed eQTL genotypes don't match its
   inferred eQTL genotype, we conclude that the labels for one or the
   other are incorrect. And we might be able to find another row in
   the inferred eQTL genotypes that matches its observed genotypes.
}
\end{frame}



\begin{frame}[c]{Prop'n mismatches}
\figh{Figs/distmatall.png}{0.85}
\note{
  For each pair of samples, one DNA (genotype) sample and one RNA
  (gene expression) sample, we get a measure of distance as the
  proportion of mismatches between the observed eQTL genotypes and the
  inferred eQTL genotypes.

  Here's a picture of this distance matrix. It should be blue along
  the diagonal and red everywhere else.
}
\end{frame}

\begin{frame}[c]{Prop'n mismatches}
\figh{Figs/distmat001.pdf}{0.85}
\note{
  And if we look at the first 100 samples, that's exactly what we see:
  the samples are close to themselves and not to anyone else.
}
\end{frame}

\begin{frame}[c]{Prop'n mismatches}
\figh{Figs/distmat201.pdf}{0.85}
\note{
  But if we look at the middle 100 samples, we find a whole bunch of
  off-by-one and off-by-two errors. The samples are quite different
  from the corresponding one, but their close to the one next to it or
  two over.
}
\end{frame}




\begin{frame}[c]{Genotype mix-ups}
\figh{Figs/plate_errors.pdf}{0.85}
\note{
  Even more incriminating, though, is the information about the
  locations of the DNA samples. DNA samples were arrayed in a set of
  six 8$\times$12 plates. In this figure, the black dots indicate the
  correct DNA sample was placed in the correct well, while the arrows
  point from where a DNA sample should have been to where it actually
  ended up.

  Two of the plates look fine, while half of each of two plates are
  entirely messed up.
}
\end{frame}


\begin{frame}[c]{Plate 1631}
\figh{Figs/plate_errors_1631.png}{0.65}
\note{
  Plate 1631 is a good example. Again, black dots indicate that the
  correct DNA was placed in the correct well.

  The little orange and purple arrow
  heads indicate that sample in well D7 is of unknown origin, and the
  sample that should have been there was lost.

  The pink circle around D2 indicates that that sample was duplicated:
  it was placed in the correct well (the black dot), but it was also
  placed in well B3. The sample that was supposed to be in B3 was
  placed in B4, the sample that was supposed to be in B4 was in E3,
  and the sample that was supposed to be in E3 was lost.

  (The purple arrow head for D7 means that the DNA was lost but that
  there is expression data for that sample, while the green arrow head
  for E3 means that the DNA was lost but there is no expression data
  for that sample.)
}
\end{frame}

\begin{frame}[c]{Plates 1632 and 1630}
\figh{Figs/plate_errors_1632_n_1630.png}{0.85}
\note{
  Plates 1632 and 1630 are where most of the problems are. There are
  some long-range swaps and other misplacements of samples, but most
  of the problems are due to a series of off-by-one and off-by two
  errors. Note that the red X's indicate DNAs that were omitted due as
  being of bad quality (possibly mixtures).
}
\end{frame}



\begin{frame}[c]{E vs E}
\only<1|handout 0>{\figh{Figs/eve_1.pdf}{0.85}}
\only<2|handout 0>{\figh{Figs/eve_2.pdf}{0.85}}
\only<3|handout 0>{\figh{Figs/eve_3.jpg}{0.85}}
\only<4|handout 0>{\figh{Figs/eve_3b.pdf}{0.85}}
\only<5|handout 0>{\figh{Figs/eve_3c.pdf}{0.85}}
\only<6|handout 0>{\figh{Figs/eve_3d.pdf}{0.85}}
\only<7|handout 0>{\figh{Figs/eve_4.pdf}{0.85}}
\only<8|handout 0>{\figh{Figs/eve_5.pdf}{0.85}}
\only<9|handout 0>{\figh{Figs/eve_6.pdf}{0.85}}
\only<10|handout 0>{\figh{Figs/eve_7.pdf}{0.85}}
\only<11>{\figh{Figs/eve_8.pdf}{0.85}}
\note{
   We can use the same trick to look for mix-ups among the gene
   expression data sets.

   The basic scheme is to first identify a subset of expression traits
   that are highly correlated between two tissues.

   Then look at the correlation between samples, using just that
   subset of expression traits.

   When a sample is correctly labeled in both tissues, the expression
   values should be correlated. If not, we may find another sample in
   one tissue that is correlated, to indicate the true label.

   Again, we make use of the multiple tissues to figure out the truth.
   If we had just two tissues we could see that they were mixed up but
   not which was the correct label.
}
\end{frame}

\begin{frame}[c]{Expression mix-ups}
\figh{Figs/expr_swaps.pdf}{0.85}
\note{
  Here are the set of mix-ups I found in the expression data. The
  arrows point from the correct label to how it appeared.

  Each tissue had some mistakes; hypothalmous was the worst. The pink
  circles indicate a sample duplicate. So, for example, in islet
  sample 3295 was correctly labeled but also appeared in duplicate
  with one sample labelled as 3296. The 3296 islet sample was lost.

  Adipose had a 3-way swap. 3187 was labelled as 3200 which was
  labelled as 3188 which was labelled as 3187. Note that most of the
  problems concern sample numbers that are close (but not necessarily
  immediately adjacent) in number.

  The general idea here has wide application for high-throughput data,
  generally. If you have mutiple rectangles of data whose rows are
  supposed to correspond, you should check to see if they do correspond.
  The strategy we used for aligning two expression datasets could
  work with little change in much broader contexts.

  Remember: all of these mistakes, including the 20\% sample mix-ups
  in the DNA, were discovered by following up on a set of just 16
  samples (out of about 500) whose sex didn't match their X chromosome
  genotype.
}
\end{frame}









\begin{frame}[c]{}


\centerline{\Large Follow up artifacts}

\bigskip \bigskip

\centerline{\large \hilit They might be the most interesting results}


\note{
  Another story to emphasize the importance of following up on artifacts.
}

\end{frame}



\begin{frame}[c]{}

\figh{Figs/mfdmaps_paper.png}{0.9}

\note{
  After I finished my PhD, I did a postdoc with a geneticist, Jim
  Weber, at the Marshfield Clinic. My central project was to develop
  new human genetic maps.
}

\end{frame}




\begin{frame}[c]{Eucalypt genetic map}

\figh{Figs/eucalypt_map.pdf}{0.75}

\vspace{5mm}

\hfill {\lolit \scriptsize
Byrne et al., Theor Appl Genet 91:869--875, 1995}

\note{
  A genetic map specifies the order of a set of markers along
  chromosomes.

  This is part of a genetic map for eucalyptus trees. It is the first
  map that I had looked at in detail.

  The original genetic maps were for observeable mutations, in
  Drosophila (fruit flies). Later markers were more directly
  DNA-based, and really chosen due to the convenience of measurement.
}

\end{frame}





\begin{frame}[c]{Meiosis}

\figh{Figs/meiosis.png}{0.95}

\note{
  Distances on a genetic map are according to recombination at
  meiosis. Meiosis is the cell division process that produces sperm
  and egg cells. DNA duplicates, and then homologous chromosomes find
  each other and become intimately associated with each other and then
  actually exchange material at locations called chiasmata. Two cell
  divisions later you have gametes with one copy of each chromosome,
  which will generally be mosaics of the original chromosomes, with
  the points of exchange called crossovers.

  Distance on a genetic map is measured by the frequency of
  crossovers. Two points are d cM apart if there is an average of d
  crossovers in the interval per 100 meiotic products.
}

\end{frame}




\begin{frame}[c]{CEPH pedigrees}

\figw{Figs/ceph_pedigrees.pdf}{1.0}

\note{
   In my postdoc, I focused on data on a set of large 8 human
   families. A mother/father pair with 10-15 offspring. Most of the
   families also included data on the grandparents.
}

\end{frame}




\begin{frame}{Crossover locations}

\vspace{2mm}

\figh{Figs/xoloc.jpg}{0.75}

\vspace{4mm}

\hfill {\scriptsize \lolit
Broman and Weber, Am J Hum Genet 66:1911--1926, 2000}

\note{
   What I was really interested in was crossover interference: the
   tendency of the crossovers to not be too close together on
   chromosomes. The open and hatched segments here are the
   grandmother's and grandfather's DNA, and the black bars are the
   intervals in which crossovers occurred.

   I wanted to look at was this dependence in
   crossover locations.
}

\end{frame}




\begin{frame}[c]{}

\figh{Figs/xoi_paper.png}{0.9}

\note{
  I did then get to my analysis of crossover interference (the
  tendency of crossovers to not be too close together).
}

\end{frame}



\begin{frame}{Crossover interference}

\figh{Figs/xodist.jpg}{0.8}

\vspace{3mm}

\hfill {\scriptsize \lolit Broman and Weber, Am J Hum Genet 66:1911--1926, 2000}

\note{
   A main part of the result concerned fitting different models to the
   inter-crossover distance data.  One model fit much better than others.
}
\end{frame}



\begin{frame}[c]{Maternal chr 8}
\figw{Figs/chr8m.png}{1.0}

\note{
  But on one particular chromosome (maternal chromosome 8), my
  favorite model really didn't fit well at all.
}

\end{frame}





\begin{frame}{Apparent triple XOs}

\figh{Figs/inversion_genotypes.jpg}{0.83}

\vspace{2mm}

\hfill {\scriptsize \lolit Broman et al., In: \emph{Science and Statistics: A Festschrift for Terry Speed}, 2003}

\note{
  I could have just left it at that, but I was curious about what was
  going on, and in studying the problem, I found that there were two
  families that showed an apparent triple-crossover event in a small
  region. This really shouldn't happen.

  My initial reaction was that I had the marker order messed up; if I
  were to invert this region, the triple crossovers would become
  single crossovers.

  But there were other families that showed a crossover in the region.
  If I invert the region, these single crossovers will become triple
  crossovers.

  So then I thought: suppose the region is inverted in these two
  families but not in the other families? This was a pretty crazy
  idea, because the region is quite large (12 cM, which turned out to
  be about 5 Mbp), and we would need individuals to be homozygous for
  each of the two orientations to have recombination occur.

  So a crazy idea: a very long inversion polymorphism where the two
  orientations were each reasonably common.
}

\end{frame}


\begin{frame}{Chr 8p inversion}

\figh{Figs/inversion_fish.jpg}{0.83}

\vspace{2mm}

\hfill {\scriptsize \lolit Broman et al., In: \emph{Science and Statistics: A Festschrift for Terry Speed}, 2003}

\note{
  I posed the hypothesis to my postdoc advisor, who talked to a friend
  whose lab had the ability to investigate this sort of thing, and
  sure enough, we had discovered the largest common inversion
  polymorphism in the human genome.

  This picture shows chromosome 8 with the green and red lighting up
  the two ends of the region. On the left, green is above red on both
  chromosomes. On the right, red is above green on both chromosomes,
  and in the middle green is above red on one chromosome and red is
  above green on the other.

  So this is the best possible example of the importance of following
  up artifacts. Lack of model fit for a particular chromosome led me
  to investigate the cause of the problem, which led me to postulate
  this idea of an inversion polymorphism, which really seemed
  kind of crazy at the time.  But it turned out to be real, and it's
  the coolest thing I've discovered in all my work as a data
  scientist.
}

\end{frame}




\begin{frame}{Capturing EDA}

\vspace{24pt}

\bi
\item what were you trying to do?
\item what you're thinking about?
\item what did you observe?
\item what did you conclude, and why?
\ei

\note{We want to be able to capture the full outcome of exploratory
  data analysis.

  But we don't want to inhibit the creative flow. How to capture this
  stuff?
}
\end{frame}


\begin{frame}{Avoid}

\vspace{24pt}

\bi
\item ``How did I create this plot?''
\item ``Why did I decide to omit those six samples?''
\item ``Where (on the web) did I find these data?''
\item ``What was that interesting gene?''
\ei

\note{I've said all of these things to myself.
}
\end{frame}



\begin{frame}{Basic principles}

\vspace{24pt}

\bi
\item[] {\hilit Step 1}: slow down and document.
\item[] {\hilit Step 2}: have sympathy for your future self.
\item[] {\hilit Step 3}: have a system.
\ei

\note{I can't emphasize these things enough.

  If you're not {\nhilit thinking} about keeping track of things, you
  won't keep track of things.

  One thing I like to do: write a set of comments describing my basic
  plan, and then fill in the code afterwards. It forces you to think
  things through, and then you'll have at least a rough sense of what
  you were doing, even if you don't take the time to write further
  comments.
}
\end{frame}





\begin{frame}{Capturing EDA}

\bbi
\item copy-and-paste from a script
\item grab code from the log (e.g., {\tt .Rhistory})
\item Write an informal report (Rmd or Jupyter)
\item Write code for use with the KnitR function {\tt spin()}
\bi
\item[] Comments like \; {\hilit \tt \#' This will become text}
\item[] Chunk options like so: \; {\hilit \tt \#+ chunk\_label, echo=FALSE}
\ei
\ei

\note{
  The creative flow in data exploration is something I don't want to
  stifle, but it's really important to capture the work so that it can
  be later reproduced.

  There are a number of techniques you can use to capture the EDA
  process. You don't need to save all of the figures, but you do need
  to save the code and write down your motivation, observations, and
  conclusions.

  I usually start out with a plain R file and then move to more formal
  R Markdown. knitr::spin() seems an interesting alternative, when
  you're writing more code than text.
}

\end{frame}





\begin{frame}[c]{}

\vspace{8mm}

  \Large
{
\color{title}
  \centering

  If you torture the data long enough, \\
  it will confess to anything.

}

  \vspace{8mm}
  \hfill -- Tukey

\note{
  When you do find something interesting, it's important to keep in
  mind the set of things that you looked at. Don't jump in with a
  statistical test at the end; this will be especially hard to do in
  an exploratory context.

  The more things you explore, the greater the chance that you'll find
  something interesting that is really just chance association.
}

\end{frame}

\end{document}
