\documentclass[aspectratio=169,12pt,t]{beamer}
\usepackage{graphicx}
\setbeameroption{hide notes}
\setbeamertemplate{note page}[plain]
\usepackage{listings}

\input{../LaTeX/header.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% end of header
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% title info
\title{Exploratory data analysis}
\author{\href{https://kbroman.org}{Karl Broman}}
\institute{Biostatistics \& Medical Informatics, UW{\textendash}Madison}
\date{\href{https://kbroman.org}{\tt \scriptsize \color{foreground} kbroman.org}
\\[-4pt]
\href{https://github.com/kbroman}{\tt \scriptsize \color{foreground} github.com/kbroman}
\\[-4pt]
\href{https://twitter.com/kwbroman}{\tt \scriptsize \color{foreground} @kwbroman}
\\[-4pt]
{\scriptsize Slides: \href{https://kbroman.org/BMI773/eda.pdf}{\tt kbroman.org/BMI773/eda.pdf}}
}


\begin{document}

% title slide
{
\setbeamertemplate{footline}{} % no page number here
\frame{
  \titlepage

\note{
   This lecture concerns exploratory data analysis. Techniques for the
   creative investigation of data, to identify problems and generate
   ideas.
}
} }








\begin{frame}[c]{}

\only<1>{
  \Large
  \color{title}
  \centering
  What is exploratory data analysis?
}

\only<2|handout 0>{
  \bigskip \bigskip

  \figh{Figs/eda_cover.jpg}{0.95}
}

\note{
  What is exploratory data analysis? The term comes from John Tukey.
  For that matter the term ``data analysis'' itself is from Tukey.

  I think he would contrast it with say ``confirmatory'' data
  analysis. Exploratory data analysis is all about creative
  investigation to generate new ideas. Confirmatory data analysis is
  about answering specific questions.
}
\end{frame}








\begin{frame}{What is exploratory data analysis?}

\bigskip \bigskip \bigskip

{\color{title}  Tukey:} \, \, Looking at data to see what it seems to say.

\onslide<2>{
\bigskip \bigskip \bigskip

\hfill \begin{minipage}{0.865\textwidth}
  It is important to understand what you {\hilit can do} \\
  before you learn to measure how {\hilit well} you seem to have
  {\hilit done} it.
\end{minipage}
}

\note{
  Here is what Tukey says in the preface of his book. He defines
  exploratory data analysis as ``looking at data to see what it seems
  to say.''
}
\end{frame}








\begin{frame}{Uses of EDA}

  \bbi
\item Get a sense of things
\item Data diagnostics (quality control)
\item Hoping for an ``a-ha'' moment
\item Following up ``huh'' moments
  \ei

\note{
  What is exploratory data analysis good for?

  Personally, I'm either trying to get a sense of things (as Tukey
  said, figure out what is it that you can do with the data), or I'm
  trying to identify potential problems in the data (data cleaning).

  I'm usually hoping that my explorations will lead some new insight
  that I wouldn't otherwise have achieved. But in practice, I'm
  usually following up on some puzzling aspect of the problem.
}
\end{frame}








\begin{frame}{Data diagnostics: principles}

  \vspace{-7mm}

  \bbi
\item What might have gone wrong?
\item How could it be revealed?
\item Make lots of plots
  \bi
\item scatterplots
\item plots against time
\item consider taking logs
  \ei
\item Check consistency between files
\item Re-calculate derived variables and check that they match
\item Outliers
  \bi
\item Real or error?
\item Are the results affected?
  \ei
\onslide<2>{\item \hilit Don't trust anyway, including yourself}
  \ei

\note{
  Let's start by looking at data diagnostics, sometimes called data
  cleaning. Our goal is to identify problems in the data, and I feel
  the best way to do that is to anticipate the problems and target
  them specifically: what might have gone wrong? how can we tell?

  But further, just make lots of plots. For high-dimensional data it
  can be tricky. Think about how to summarize the results in ways that
  can reveal the sorts of odd problems. But just make lots of
  scatterplots and plots of variables against time. For measurements
  that span multiple orders of magnitude, you usually want to take
  logs.

  Also, check consistency between files. If subjects are present in
  one file but missing from another, is that as expected or could part
  of a file be missing? If measurements are repeated in multiple
  files, do they match? Re-calculate any derived variables and check
  that they match.

  For outliers, you want to figure out if they are real or an error.
  Do they affect the results? If they're errors, fix them. If they're
  real but don't affect the results, no worries. If they're real and
  affect the results, worry.
}
\end{frame}


\begin{frame}[c]{Batch effect}

\only<1>{\figh{Figs/il3.pdf}{0.85}}
\only<2>{\figh{Figs/il3_log.pdf}{0.85}}

\note{
Here's an example of a clear batch effect. You can really only tell if
you plot the variable by the order of measurement, and it's much more
clear if you take logs.
}

\end{frame}





\begin{frame}[c]{Messed up units}

\figh{Figs/adipose_weight.pdf}{0.85}

\note{
Here's a case where a variable was recorded in the wrong units (g
rather than mg) for a few individuals)

}

\end{frame}




\begin{frame}[c]{Outliers}

\figh{Figs/body_weight.pdf}{0.85}

\note{
In this particular case, it turned out that the day 10 weights for two
subjects got swapped.

When you look at this sort of situation, ask yourself how you might
find this problem if you have 20 weight measurements and 1500
individuals.
}

\end{frame}




\begin{frame}{Weird stuff I've seen}

  \vspace{-7mm}

  \bbi
  \item 500 worksheet excel file where the middle 100 worksheets have
    the variables arranged in a different order
  \item Weird rounding patterns
  \item Missing values that shouldn't be, because derived values are
    not missing
  \item Categorical data with inconsistent categories
  \item Missing value codes that weren't mentioned and that could be
    real values (e.g., 999)
  \item OMG dates
  \ei

\note{
  All kinds of things get messed up in data files. It's hard to find
  it if you don't look for it; you have to check.

  When it comes to the order of variables in multiple files, {\hilit
  never} assume consistency; {\hilit always} check.
}

\end{frame}




\begin{frame}{Weird rounding}

  \figh{Figs/weird_rounding.png}{0.85}

  \note{
    Here's an example of some weird rounding in an excel file. The
    fonts aren't even consistent. This indicates that some copy and
    pasting went on, which makes me question whether there is some
    other master file that I should really be looking at.
  }

\end{frame}





\begin{frame}{Identifiers}

  \vspace{-7mm}

  \bbi
  \item Are the subject IDs unique?
  \item Are there subject or gene IDs that don't fit the typical
    pattern?
    \bi
  \item {\tt 1e6} vs {\tt 100000}
  \item hyphens turned into periods
  \item IDs that became dates
    \ei
  \item Subjects in one file but not in another and vice versa
  \ei

\note{
  IDs are really important but they can be screwed up in all kinds of
  ways. R can mess them up; Excel can mess them up. They can get
  messed up repeatedly by your collaborators, no matter how hard you
  work to preserve them.
}

\end{frame}






\begin{frame}{Missing values}

  \bbi
  \item As intended?
  \item Below detection limit?
  \item Telling you something about sample quality?
  \item Introducing bias?
  \ei

\note{
  It can be important to look at the pattern of missing data. For
  genotyping and sequencing assays, a high rate of missing data often
  indicates poor quality samples.

  But also, are the missing data really as intended?

  Could they maybe be values below the detection limit of the assay?
  And does that mean that they should be just treated as small values,
  or omitted?

  Is the nature of the missing data going to bias your conclusions?
}

\end{frame}




\begin{frame}{Fitting a model can help}


\note{
  Sometimes, it's helpful to fit some sort of model. Particularly if
  you have very large quantities of data, you could then better
  identify problem samples or data points, for example by looking for
  large residuals.

  Example: mouse body weight data (where fitting smooth curves also
  led us to look at the derivatives, which were super interesting)

}

\end{frame}




\begin{frame}[c]{}


\centerline{\Large Follow up artifacts}

\bigskip \bigskip

\centerline{\large \hilit They might be the most interesting results}


\note{
  Another story to emphasize the importance of following up on artifacts.
}

\end{frame}



\begin{frame}[c]{}

\figh{Figs/mfdmaps_paper.png}{0.9}

\note{
  After I finished my PhD, I did a postdoc with a geneticist, Jim
  Weber, at the Marshfield Clinic. My central project was to develop
  new human genetic maps.
}

\end{frame}




\begin{frame}[c]{Eucalypt genetic map}

\figh{Figs/eucalypt_map.pdf}{0.75}

\vspace{5mm}

\hfill {\lolit \scriptsize
Byrne et al., Theor Appl Genet 91:869--875, 1995}

\note{
  A genetic map specifies the order of a set of markers along
  chromosomes.

  This is part of a genetic map for eucalyptus trees. It is the first
  map that I had looked at in detail.

  The original genetic maps were for observeable mutations, in
  Drosophila (fruit flies). Later markers were more directly
  DNA-based, and really chosen due to the convenience of measurement.
}

\end{frame}





\begin{frame}[c]{Meiosis}

\figh{Figs/meiosis.png}{0.95}

\note{
  Distances on a genetic map are according to recombination at
  meiosis. Meiosis is the cell division process that produces sperm
  and egg cells. DNA duplicates, and then homologous chromosomes find
  each other and become intimately associated with each other and then
  actually exchange material at locations called chiasmata. Two cell
  divisions later you have gametes with one copy of each chromosome,
  which will generally be mosaics of the original chromosomes, with
  the points of exchange called crossovers.

  Distance on a genetic map is measured by the frequency of
  crossovers. Two points are d cM apart if there is an average of d
  crossovers in the interval per 100 meiotic products.
}

\end{frame}




\begin{frame}[c]{CEPH pedigrees}

\figw{Figs/ceph_pedigrees.pdf}{1.0}

\note{
   In my postdoc, I focused on data on a set of large 8 human
   families. A mother/father pair with 10-15 offspring. Most of the
   families also included data on the grandparents.
}

\end{frame}




\begin{frame}{Crossover locations}

\vspace{2mm}

\figh{Figs/xoloc.jpg}{0.75}

\vspace{4mm}

\hfill {\scriptsize \lolit
Broman and Weber, Am J Hum Genet 66:1911--1926, 2000}

\note{
   What I was really interested in was crossover interference: the
   tendency of the crossovers to not be too close together on
   chromosomes. The open and hatched segments here are the
   grandmother's and grandfather's DNA, and the black bars are the
   intervals in which crossovers occurred.

   I wanted to look at was this dependence in
   crossover locations.
}

\end{frame}




\begin{frame}[c]{}

\figh{Figs/xoi_paper.png}{0.9}

\note{
  I did then get to my analysis of crossover interference (the
  tendency of crossovers to not be too close together).
}

\end{frame}



\begin{frame}{Crossover interference}

\figh{Figs/xodist.jpg}{0.8}

\vspace{3mm}

\hfill {\scriptsize \lolit Broman and Weber, Am J Hum Genet 66:1911--1926, 2000}

\note{
   A main part of the result concerned fitting different models to the
   inter-crossover distance data.  One model fit much better than others.
}
\end{frame}



\begin{frame}[c]{Maternal chr 8}
\figw{Figs/chr8m.png}{1.0}

\note{
  But on one particular chromosome (maternal chromosome 8), my
  favorite model really didn't fit well at all.
}

\end{frame}





\begin{frame}{Apparent triple XOs}

\figh{Figs/inversion_genotypes.jpg}{0.83}

\vspace{2mm}

\hfill {\scriptsize \lolit Broman et al., In: \emph{Science and Statistics: A Festschrift for Terry Speed}, 2003}

\note{
  I could have just left it at that, but I was curious about what was
  going on, and in studying the problem, I found that there were two
  families that showed an apparent triple-crossover event in a small
  region. This really shouldn't happen.

  My initial reaction was that I had the marker order messed up; if I
  were to invert this region, the triple crossovers would become
  single crossovers.

  But there were other families that showed a crossover in the region.
  If I invert the region, these single crossovers will become triple
  crossovers.

  So then I thought: suppose the region is inverted in these two
  families but not in the other families? This was a pretty crazy
  idea, because the region is quite large (12 cM, which turned out to
  be about 5 Mbp), and we would need individuals to be homozygous for
  each of the two orientations to have recombination occur.

  So a crazy idea: a very long inversion polymorphism where the two
  orientations were each reasonably common.
}

\end{frame}


\begin{frame}{Chr 8p inversion}

\figh{Figs/inversion_fish.jpg}{0.83}

\vspace{2mm}

\hfill {\scriptsize \lolit Broman et al., In: \emph{Science and Statistics: A Festschrift for Terry Speed}, 2003}

\note{
  I posed the hypothesis to my postdoc advisor, who talked to a friend
  whose lab had the ability to investigate this sort of thing, and
  sure enough, we had discovered the largest common inversion
  polymorphism in the human genome.

  This picture shows chromosome 8 with the green and red lighting up
  the two ends of the region. On the left, green is above red on both
  chromosomes. On the right, red is above green on both chromosomes,
  and in the middle green is above red on one chromosome and red is
  above green on the other.

  So this is the best possible example of the importance of following
  up artifacts. Lack of model fit for a particular chromosome led me
  to investigate the cause of the problem, which led me to postulate
  this idea of an inversion polymorphism, which really seemed
  kind of crazy at the time.  But it turned out to be real, and it's
  the coolest thing I've discovered in all my work as a data
  scientist.
}

\end{frame}




\begin{frame}{Capturing EDA}

\vspace{24pt}

\bi
\item what were you trying to do?
\item what you're thinking about?
\item what did you observe?
\item what did you conclude, and why?
\ei

\note{We want to be able to capture the full outcome of exploratory
  data analysis.

  But we don't want to inhibit the creative flow. How to capture this
  stuff?
}
\end{frame}


\begin{frame}{Avoid}

\vspace{24pt}

\bi
\item ``How did I create this plot?''
\item ``Why did I decide to omit those six samples?''
\item ``Where (on the web) did I find these data?''
\item ``What was that interesting gene?''
\ei

\note{I've said all of these things to myself.
}
\end{frame}



\begin{frame}{Basic principles}

\vspace{24pt}

\bi
\item[] {\hilit Step 1}: slow down and document.
\item[] {\hilit Step 2}: have sympathy for your future self.
\item[] {\hilit Step 3}: have a system.
\ei

\note{I can't emphasize these things enough.

  If you're not {\nhilit thinking} about keeping track of things, you
  won't keep track of things.

  One thing I like to do: write a set of comments describing my basic
  plan, and then fill in the code afterwards. It forces you to think
  things through, and then you'll have at least a rough sense of what
  you were doing, even if you don't take the time to write further
  comments.
}
\end{frame}





\begin{frame}{Capturing EDA}

\bbi
\item copy-and-paste from a script
\item grab code from the log (e.g., {\tt .Rhistory})
\item Write an informal report (Rmd or Jupyter)
\item Write code for use with the KnitR function {\tt spin()}
\bi
\item[] Comments like \; {\hilit \tt \#' This will become text}
\item[] Chunk options like so: \; {\hilit \tt \#+ chunk\_label, echo=FALSE}
\ei
\ei

\note{
  The creative flow in data exploration is something I don't want to
  stifle, but it's really important to capture the work so that it can
  be later reproduced.

  There are a number of techniques you can use to capture the EDA
  process. You don't need to save all of the figures, but you do need
  to save the code and write down your motivation, observations, and
  conclusions.

  I usually start out with a plain R file and then move to more formal
  R Markdown. knitr::spin() seems an interesting alternative, when
  you're writing more code than text.
}

\end{frame}





\begin{frame}[c]{}

\vspace{8mm}

  \Large
{
\color{title}
  \centering

  If you torture the data long enough, \\
  it will confess to anything.

}

  \vspace{8mm}
  \hfill -- Tukey

\note{
  When you do find something interesting, it's important to keep in
  mind the set of things that you looked at. Don't jump in with a
  statistical test at the end; this will be especially hard to do in
  an exploratory context.

  The more things you explore, the greater the chance that you'll find
  something interesting that is really just chance association.
}

\end{frame}

\end{document}
